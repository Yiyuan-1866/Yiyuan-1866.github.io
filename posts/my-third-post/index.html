<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Cat">
    <link rel="icon" type="image/x-icon" href="https://yiyuan-1866.github.io/img/logo.svg">
    
    <link rel="stylesheet" href="https://yiyuan-1866.github.io/css/style.min.1dac2dce58058802a69e8c1e3ae7a2820fa9411cff0cded4211b8a1403b3b8327c23f39304b5650b1ffe9b747ea64029f9c811425cf1ffa0eb081ab9ccec871b.css" integrity="sha512-HawtzlgFiAKmnoweOueigg&#43;pQRz/DN7UIRuKFAOzuDJ8I/OTBLVlCx/&#43;m3R&#43;pkAp&#43;cgRQlzx/6DrCBq5zOyHGw==" crossorigin="anonymous"> 
    

</head>

<title>
    
     Poisson Process | Exploring the Echoes
   
</title> 

<body> 
<header>
    <div class="cat">
     <h1><a href="https://yiyuan-1866.github.io/">Exploring the Echoes</a></h1>
    
     <ul class="header-link">
       
       <li><a class="link" href="/">Home</a></li>
       
       <li><a class="link" href="/posts/">Blog</a></li>
       
       <li><a class="link" href="/contact/">Contact</a></li>
       
       <li><a class="link" href="/about/">About</a></li>
       
     </ul>
   </div>
</header>

l<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
</script>
<div id="content">

<div class="container">
		<article>
			<h1 class="head-blog">Poisson Process</h1>
			<div class="time">Dec 17, 2023</div>
			<div>
				<p>You can find the PDF version of this content <a href="https://drive.google.com/file/d/1T3tmlrMIaD8xMnJ3-3D65IBBchsWfYiR/view">here</a>.</p>
<h2 id="1-basic-properties-of-poisson-processes">§1 Basic Properties of Poisson Processes</h2>
<p>The Poisson process is the simplest counting process, denoted by $ N(t) $, which counts the number of events (discrete states) that occur over a continuous time period. To analyze this process, we use joint probability techniques. We now begin studying the Poisson Process.</p>
<h3 id="definition-11">Definition 1.1</h3>
<p>A Poisson process is a stochastic process characterized by the following:</p>
<ul>
<li>$ N(0) = 0 $</li>
<li><strong>Independent Increments:</strong> For any $ t_1 \leq t_2 \leq t_3 \leq t_4 $, the difference $ N(t_2) - N(t_1) $ is independent of $ N(t_4) - N(t_3) $.</li>
<li><strong>Stationary Increments:</strong> For any $ s \leq t $, the difference $ N(t) - N(s) $ depends only on $ t - s $.</li>
<li><strong>Sparsity:</strong> As $ t \to 0 $, $ \frac{P(N(t) \geq 2)}{P(N(t)=1)} $ tends to zero.</li>
</ul>
<p>Since the Poisson distribution is discrete, we use the moment generating function as our main tool.</p>
<h3 id="definition-12">Definition 1.2</h3>
<p>Let $ X $ be a random variable. Its moment generating function is defined as $ G_X(z) = E\left( z^X \right) $, where $ z \in \mathbb{C} $.</p>
<h3 id="question-13">Question 1.3</h3>
<p>Recall the definition of the characteristic function $ \phi_X(\omega) = E(\exp(j \omega X)) $. How does this compare to $ G_X(z) = E(z^X) $?</p>
<h2 id="11-moment-generating-function-of-poisson-process">§1.1 Moment Generating Function of Poisson Process</h2>
<p>To find the moment generating function of the Poisson process, we begin with:</p>
<p>$$
G_{N(t)}(z) = E\left(z^{N(t)}\right)
$$</p>
<p>Then,</p>
<p>$$
\frac{d}{dt} G_{N(t)}(z) = \lim_{\Delta t \to 0} \frac{G_{N(t + \Delta t)}(z) - G_{N(t)}(z)}{\Delta t}
$$</p>
<p>$$
= \lim_{\Delta t \to 0} \frac{E\left(z^{N(t + \Delta t)} - z^{N(t)}\right)}{\Delta t}
$$</p>
<p>$$
= \lim_{\Delta t \to 0} \frac{E\left(z^{N(t)}\right) E\left(z^{N(\Delta t)} - 1\right)}{\Delta t}
$$</p>
<p>$$
= G_{N(t)}(z) \lim_{\Delta t \to 0} \frac{E\left(z^{N(\Delta t)} - 1\right)}{\Delta t}
$$</p>
<p>Now, consider $ E\left(z^{N(\Delta t)} - 1\right) $:</p>
<p>$$
E\left(z^{N(\Delta t)} - 1\right) = P(N(\Delta t) = 0) - 1 + z P(N(\Delta t) = 1) + \sum_{k \geq 2} z^k P(N(\Delta t) = k)
$$</p>
<p>From this, we derive:</p>
<ol>
<li>Let $ g(t) = P(N(t) = 0) $. Then, $ g(t) = P(N(t) = 0) = P(N(s) = 0, N(t) = 0) = P(N(s) = 0) P(N(t - s) = 0) = g(s) g(t - s) $, for all $ 0 \leq s \leq t $. Thus, $ g(t) $ has the form $ C \cdot e^{-\lambda t} $. Since $ g(0) = 1 $, we deduce that $ P(N(\Delta t) = 0) = e^{-\lambda \Delta t} $. Therefore, $ P(N(\Delta t) = 0) - 1 = -\lambda \Delta t + o(\Delta t) $.</li>
<li>Since $ P(N(\Delta t) = 1)\left(1 + \frac{P(N(\Delta t) \geq 2)}{P(N(\Delta t) = 1)}\right) = 1 - P(N(\Delta t) = 0) $, letting $ \Delta t \to 0 $, we get:</li>
</ol>
<p>$$
\lim_{\Delta t \to 0} P(N(\Delta t) = 1) = \lambda \Delta t
$$</p>
<ol start="3">
<li>As $ \Delta t \to 0 $, $ \frac{P(N(\Delta t) \geq 2)}{P(N(\Delta t) = 1)} \to 0 $. The series $ \sum_{k=2}^{\infty} z^k P(N(\Delta t) = k) \to 0 $ for any $ |z| \leq 1 $. Thus,</li>
</ol>
<p>$$
\lim_{\Delta t \to 0} \frac{E\left(z^{N(\Delta t)} - 1\right)}{\Delta t} = -\lambda + \lambda z = \lambda (z - 1)
$$</p>
<p>Finally, we obtain the moment generating function of the Poisson process:</p>
<p>$$
G_{N(t)}(z) = \exp(\lambda(z - 1) t)
$$</p>
<p>This implies that $ P(N(t) = k) = \frac{(\lambda t)^k}{k!} \exp(-\lambda t) $, showing that $ N(t) $ follows a Poisson distribution with parameter $ \lambda t $. The intensity of the Poisson process is $ \lambda = \frac{E(N(t))}{t} $.</p>
<h3 id="question-14">Question 1.4</h3>
<p>Is the Poisson process wide-sense stationary?</p>
<h3 id="remark-15">Remark 1.5</h3>
<p>The Poisson process is not wide-sense stationary due to its &ldquo;jumping&rdquo; and &ldquo;waiting&rdquo; behavior.</p>
<p>Now, let’s consider the interval between two events.</p>
<p>$$
F_{T_1}(t) = P(T_1 \leq t) = 1 - P(N(t) = 0) = 1 - e^{-\lambda t} \quad (t \geq 0)
$$</p>
<p>As a result, $ f_{T_1}(t) = \lambda e^{-\lambda t} $, which means $ T_1 $ follows an exponential distribution.</p>
<h3 id="question-16">Question 1.6</h3>
<p>Prove that $ T_1, T_2, \dots, T_n $ are independently and identically distributed as $ \text{Exp}(\lambda) $.</p>
<h3 id="question-17">Question 1.7</h3>
<p>Denote the time of the $ k $-th event as $ S_k = \sum_{i=1}^{k} T_i $. Find the distribution of $ S_k $.</p>
<h3 id="solution-18">Solution 1.8</h3>
<p>The characteristic function of the sum of $ k $ independent exponential random variables $ T_1, T_2, \dots, T_k $ with parameter $ \lambda $ is the product of their individual characteristic functions. The characteristic function of an exponential distribution with parameter $ \lambda $ is:</p>
<p>$$
\phi_{T_i}(\omega) = \frac{\lambda}{\lambda - j\omega}
$$</p>
<p>Thus, the characteristic function of $ S_k $ is:</p>
<p>$$
\phi_{S_k}(\omega) = \prod_{i=1}^{k} \phi_{T_i}(\omega) = \left( \frac{\lambda}{\lambda - j\omega} \right)^k
$$</p>
<p>By taking the inverse Fourier transform, we can find the probability distribution of $ S_k $, which is a gamma distribution with shape parameter $ k $ and scale parameter $ \frac{1}{\lambda} $, denoted as $ \Gamma(k, \frac{1}{\lambda}) $.</p>
<p>Thus, $ S_k $ has a gamma distribution with shape parameter $ k $ and scale parameter $ \frac{1}{\lambda} $, denoted as $ \Gamma(k, \frac{1}{\lambda}) $.</p>
<h3 id="remark-19">Remark 1.9</h3>
<p>This is the probability density function of a gamma distribution.</p>
<h2 id="2-generalized-poisson-process">§2 Generalized Poisson Process</h2>
<h3 id="21-non-homogeneous-poisson-process">§2.1 Non-homogeneous Poisson Process</h3>
<p>We can generalize the Poisson process by relaxing some of its conditions. Recall the definition of a Poisson process, which has three key assumptions. Let&rsquo;s start by considering the stationary condition:</p>
<h3 id="question-21">Question 2.1</h3>
<p>In the basic Poisson process, where do we use the stationary condition?</p>
<p>Since we no longer assume stationarity, we make the following assumption:</p>
<p>$$
\lim_{\Delta t \to 0} \frac{P(N(t + \Delta t) - N(t) = 0) - 1}{\Delta t} = -\lambda(t) \quad \text{as} \quad \Delta t \to 0
$$</p>
<p>Now, we need to solve the following differential equation:</p>
<p>$$
\frac{d}{dt} G_{N(t)}(z) = G_{N(t)}(z) \cdot \lambda(t)(z - 1)
$$</p>
<p>$$
G_{N(0)}(z) = 1
$$</p>
<p>Thus, we find:</p>
<p>$$
G_{N(t)}(z) = \exp\left( \int_0^t \lambda(s) ds \cdot (z - 1) \right)
$$</p>
<h3 id="remark-22">Remark 2.2</h3>
<p>After relaxing the stationarity condition, $ N(t) $ still follows a Poisson distribution with mean $ \int_0^t \lambda(s) ds $. This is called a non-homogeneous Poisson process.</p>
<p>Now, consider another situation. Let $ Z_1, Z_2, \dots, Z_n $ be i.i.d. random variables, and let $ Y(t) = \sum_{k=1}^{N(t)} Z_k $.</p>
<p>$$
G_{Y(t)}(z) = E\left( z^{Y(t)} \right)
$$</p>
<p>$$
= E_{N(t)} \left( \left( E\left( z^{Z_k} \right) \right)^{N(t)} \right)
$$</p>
<p>$$
= G_{N(t)}\left( G_Z(z) \right)
$$</p>
<p>$$
= \exp \left( \lambda t \left( G_Z(z) - 1 \right) \right)
$$</p>
<h3 id="remark-23">Remark 2.3</h3>
<p>Although $ N(t) Z_1 $ seems different from the general Poisson process, it shares the same mathematical structure!</p>
<h3 id="example-24-thinning">Example 2.4 (Thinning)</h3>
<p>Consider the following thinning example:</p>
<p>$$
X_k = \begin{cases}
0 &amp; \text{with probability } 1 - p \
1 &amp; \text{with probability } p
\end{cases}
$$</p>
<p>Thus,</p>
<p>$$
Y(t) = \sum_{k=1}^{N(t)} X_k
$$</p>
<p>$$
G_Z(z) = pz + (1 - p)
$$</p>
<p>$$
G_{Y(t)}(z) = \exp \left( \lambda t p (z - 1) \right)
$$</p>
<p>This means that $ Y(t) $ is still a Poisson process.</p>
<h3 id="example-25-superposition-of-poisson-processes">Example 2.5 (Superposition of Poisson Processes)</h3>
<p>Consider two independent Poisson processes, $ N_1(t) \sim \lambda_1 $ and $ N_2(t) \sim \lambda_2 $. The process $ \left( N_1(t) + N_2(t) \right)_t $ is also a Poisson process.</p>
<p>$$
G_{N_1(t) + N_2(t)}(z) = E\left( z^{N_1(t) + N_2(t)} \right)
$$</p>
<p>$$
= G_{N_1(t)}(z) \cdot G_{N_2(t)}(z)
$$</p>
<p>$$
= \exp \left( \lambda_1 t (z - 1) \right) \cdot \exp \left( \lambda_2 t (z - 1) \right)
$$</p>
<p>$$
= \exp \left( (\lambda_1 + \lambda_2) t (z - 1) \right)
$$</p>
<h3 id="question-26">Question 2.6</h3>
<p>What about $ N_1(t) - N_2(t) $? Is it still a Poisson process?</p>
<h3 id="solution-27">Solution 2.7</h3>
<p>No, because $ P(N_1(t) - N_2(t) &lt; 0) \neq 0 $. Therefore, it’s not a Poisson process.</p>
<h3 id="example-28-difference-of-two-poisson-processes">Example 2.8 (Difference of Two Poisson Processes)</h3>
<p>Now, let’s consider the difference between two independent Poisson processes $ N_1(t) $ and $ N_2(t) $. We want to find the distribution of $ N_1(t) - N_2(t) $.</p>
<p>The moment generating function of $ N_1(t) - N_2(t) $ can be calculated as follows:</p>
<p>$$
G_{N_1(t) - N_2(t)}(z) = E\left( z^{N_1(t) - N_2(t)} \right)
$$</p>
<p>$$
= E\left( z^{N_1(t)} \right) \cdot E\left( \left( \frac{1}{z} \right)^{N_2(t)} \right)
$$</p>
<p>$$
= \exp\left( \lambda_1 (z - 1) \right) \cdot \exp\left( -\lambda_2 \left( \frac{1}{z} - 1 \right) \right)
$$</p>
<p>$$
= \exp\left( t \left( \lambda_1 (z - 1) - \lambda_2 \left( \frac{1}{z} - 1 \right) \right) \right)
$$</p>
<p>We see that $ N_1(t) - N_2(t) $ does not follow a Poisson distribution, but it has a distribution similar to a non-homogeneous Poisson process with rate parameter $ \lambda(t) = \lambda_1 - \lambda_2 $.</p>
<h3 id="question-29">Question 2.9</h3>
<p>Consider two independent Poisson processes $ N_1(t) $ and $ N_2(t) $ with rate parameters $ \lambda_1 $ and $ \lambda_2 $, respectively. Let $ X $ be a random variable that takes the values 1 and -1 with probabilities $ \frac{\lambda_1}{\lambda_1 + \lambda_2} $ and $ \frac{\lambda_2}{\lambda_1 + \lambda_2} $, respectively. Explain how the process $ N_1(t) - N_2(t) $ is formed based on the random variable $ X $.</p>
<h2 id="22-compound-poisson-process">§2.2 Compound Poisson Process</h2>
<p>Consider a sequence of random variables $ (N(\Delta t))<em>{t \geq 0} $, representing the number of events in a time interval $ \Delta t $. Let $ \lambda_k = \lim</em>{\Delta t \to 0} \frac{P(N(\Delta t) = k)}{P(N(\Delta t) &gt; 0)} $, the probability of observing $ k $ events in an infinitesimal interval. As $ \Delta t \to 0 $, we have:</p>
<p>$$
\frac{P(N(\Delta t) = 0) - 1}{\Delta t} \to -\lambda
$$</p>
<p>$$
\frac{P(N(\Delta t) &gt; 0)}{\Delta t} \to \lambda
$$</p>
<p>where $ \lambda = \lim_{\Delta t \to 0} \frac{\mathbb{E}[N(\Delta t)]}{\Delta t} $ is the intensity of the Poisson process.</p>
<p>Furthermore:</p>
<p>$$
\frac{\mathbb{E}\left[ z^{N(\Delta t)} - 1 \right]}{\Delta t} \to -\lambda + \lambda \left( \sum_{k \geq 1} \lambda_k z^k \right)
$$</p>
<p>Let $ P(z) = \sum_{k \geq 1} \lambda_k z^k $ denote the probability generating function of $ N(\Delta t) $, and let $ G_z(z) = \sum_{k \geq 0} \lambda_k z^k $ denote its moment generating function. Then:</p>
<p>$$
G_{N(t)}(z) = \exp\left( \lambda(t)(P(z) - 1) \right)
$$</p>
<p>where $ \lambda(t) $ is the time-varying intensity of the non-homogeneous Poisson process.</p>
<p>In comparison, for compound Poisson processes:</p>
<p>$$
G_{N(t)}(z) = \exp\left( \lambda(t)\left( G_z(z) - 1 \right) \right)
$$</p>
<h2 id="23-filtered-poisson-process">§2.3 Filtered Poisson Process</h2>
<p>To generalize Poisson processes by loosening the independent increment assumption, consider the following example: a Poisson process $ N(t) $ with events $ T_1, T_2, T_3, T_4 $ and inter-event times $ S_1, S_2, S_3, S_4 $. The expected value $ E(S_4 \mid N(1) = 2) $ can be calculated as follows:</p>
<p>$$
F_{S_4}(t \mid N(1) = 2) = P(S_4 \leq t \mid N(1) = 2)
$$</p>
<p>$$
= P(N(t) \geq 4 \mid N(1) = 2)
$$</p>
<p>$$
= \frac{P(N(1) = 2; N(t) - N(1) \geq 2)}{P(N(1) = 2)}
$$</p>
<p>$$
= P(N(t - 1) \geq 2)
$$</p>
<p>$$
= 1 - \exp(-\lambda(t - 1)) - \lambda(t - 1) \exp(-\lambda(t - 1))
$$</p>
<p>The density function is:</p>
<p>$$
f_{S_4}(t \mid N(1) = 2) = \lambda^2(t - 1) \exp(-\lambda(t - 1)) \quad (t \geq 1)
$$</p>
<p>The expected value $ E(S_4 \mid N(1) = 2) $ is:</p>
<p>$$
E(S_4 \mid N(1) = 2) = \int_1^\infty t f_{S_4}(t \mid N(1) = 2) dt
$$</p>
<p>$$
= \int_1^\infty \lambda^2 t(t - 1) \exp(-\lambda(t - 1)) dt
$$</p>
<p>$$
= \int_0^\infty \lambda^2 x(x + 1) \exp(-\lambda x) dx
$$</p>
<p>$$
= \lambda\left(E(\text{Exp}(\lambda)) + \text{Var}(\text{Exp}(\lambda)) + \left(E(\text{Exp}(\lambda))\right)^2\right)
$$</p>
<p>$$
= \lambda\left(\frac{1}{\lambda} + \frac{1}{\lambda^2} + \frac{1}{\lambda^2}\right) = 1 + \frac{2}{\lambda}
$$</p>
<h3 id="question-210">Question 2.10</h3>
<p>Is there a problem with this argument? You can refer to the Inspection Paradox.</p>
<h3 id="remark-211">Remark 2.11</h3>
<p>While it is true that $ S_4 - S_3 = T_3 $ is exponentially distributed, why is $ S_3 - 1 $ still exponentially distributed?</p>
<p>Consider the following calculations:</p>
<p>$$
F_{S_1}(x \mid N(t) = 1) = P(S_1 \leq x \mid N(t) = 1)
$$</p>
<p>$$
= P(N(x) = 1 \mid N(t) = 1)
$$</p>
<p>$$
= \frac{P(N(x) = 1, N(t - x) = 0)}{P(N(t) = 1)}
$$</p>
<p>$$
= \frac{x}{t}
$$</p>
<p>Therefore, the density function is:</p>
<p>$$
f_{S_1}(x \mid N(t) = 1) = \frac{d}{dx} F_{S_1}(x \mid N(t) = 1) = \frac{1}{t}
$$</p>
<p>Thus, $ S_1 \mid N(t) = 1 \sim U(0, t) $ (uniform distribution).</p>
<p>Similarly, for two increments, we have:</p>
<p>$$
P(N(t - \Delta x_1 - \Delta x_2) = 0, N(\Delta x_1) = 1, N(\Delta x_2) = 1 \mid N(t) = 2) = \frac{\lambda^2 \Delta x_1 \Delta x_2}{\frac{(\lambda t)^2}{2}}
$$</p>
<p>This gives the joint density:</p>
<p>$$
f_{S_1, S_2}(x_1, x_2) = \frac{2}{t^2} \quad (0 \leq x_1 \leq x_2 \leq t)
$$</p>
<h3 id="remark-212">Remark 2.12</h3>
<p>There is an intrinsic relationship between $ x_1 $ and $ x_2 $, which causes us to lose independent increments in a filtered Poisson process.</p>
<p>Recall that for a non-homogeneous and compound Poisson process:</p>
<p>$$
X(t) = \sum_{k=1}^{N(t)} Z_k(t, S_k, Z_k)
$$</p>
<p>where $ N(t) $ is the counting process and $ Z_k(t, S_k, Z_k) $ represents the $ k $-th jump of the process at time $ t $ with jump size $ Z_k $ and location $ S_k $.</p>
<p>We study this process using its characteristic function:</p>
<p>$$
\phi_{Z(t)}(\omega) = E\left[\exp(j \omega Z(t))\right]
$$</p>
<p>$$
= E_{N(t)}\left[\prod_{i=1}^{N(t)} E\left[\exp(j \omega Z_k(t, S_k, Z_k)) \mid N(t)\right]\right]
$$</p>
<p>Let $ B(t, S_k) = \exp(j \omega Z_k(t, S_k, Z_k)) $ be the characteristic function of the jumps. Then,</p>
<p>$$
\phi_{Z(t)}(\omega) = E_{N(t)}\left[\left(\frac{1}{t} \int_0^t B(t, s) ds\right)^{N(t)}\right]
$$</p>
<p>$$
= \exp\left(-\lambda \int_0^t \left(E[\exp(j \omega Z(t, s)) - 1]\right) ds\right)
$$</p>
<p>where $ \lambda $ is the intensity of the process. This type of process is called a filtered Poisson process.</p>
<p>Finally, we have:</p>
<p>$$
E(Z(t)) = \lambda \int_0^t E(Z(t, s)) ds
$$</p>
<p>where $ Z(t, s) $ is the jump size at time $ t $ with location $ s $.</p>
<h3 id="example-poisson-process-at-a-bus-stop">Example: Poisson Process at a Bus Stop</h3>
<p>Consider a bus stop with operating hours $ [0, T] $, where $ n $ buses are scheduled to arrive at times $ T_1, T_2, \dots, T_n $, aiming to minimize the total waiting time of passengers. Let passengers arrive according to a Poisson process with rate $ \lambda $, and assume the buses have infinite capacity.</p>
<p>The total waiting time for passengers in the interval $ [0, T_1] $ is:</p>
<p>$$
W_1 = \sum_{k=1}^{N(T_1)} (T_1 - S_k)
$$</p>
<p>where $ N(T_1) $ is the number of passengers arriving in the interval, and $ S_k $ is the arrival time of the $ k $-th passenger. The expected waiting time is:</p>
<p>$$
E[W_1] = E_{N(T_1)}\left[N(T_1) \cdot T_1 - \sum_{k=1}^{N(T_1)} E[S_k \mid N(T_1) = n]\right]
$$</p>
<p>$$
= \frac{\lambda T_1}{2} \cdot T_1 = \frac{1}{2} \lambda T_1^2
$$</p>
<p>Thus, the total expected waiting time is:</p>
<p>$$
T = E\left[\sum_{i=1}^{n} W_i\right] = \frac{1}{2} \lambda (T_1^2 + T_2^2 + \dots + T_n^2)
$$</p>
<p>To minimize the total waiting time, we minimize $ T $ subject to $ T_1 + T_2 + \dots + T_n = T $. Using Lagrange multipliers, the optimal solution is:</p>
<p>$$
T_1 = T_2 = \dots = T_n = \frac{T}{n}
$$</p>
<p>Thus, the optimal scheduling is to have buses arrive at equal intervals of $ T/n $.</p>
<h2 id="24-the-cramér-lundberg-model-for-insurance-risk">§2.4 The Cramér-Lundberg Model for Insurance Risk</h2>
<p>In the Cramér-Lundberg model, $ V(t) $ represents the surplus of an insurance company at time $ t $:</p>
<p>$$
V(t) = V_0 + c(t) - \sum_{k=1}^{N(t)} Z_k \exp\left(-\alpha(t - \tau_k)\right)
$$</p>
<p>where $ V_0 $ is the initial surplus, $ c(t) $ is the premium income rate, $ N(t) $ is a Poisson process with rate $ \lambda $, $ \tau_k $ is the arrival time of the $ k $-th claim, $ Z_k $ is the size of the $ k $-th claim, and $ \alpha $ is a constant. Define $ Y(t) = \sum_{k=1}^{N(t)} Z_k \exp(\alpha \tau_k) $, representing the total discounted claim amount up to time $ t $.</p>
<p>The expected total discounted claim amount is:</p>
<p>$$
E[Y(T)] = E_{N(t)}\left[\sum_{k=1}^{n} \exp(\alpha \tau_k) E[Z_k \mid N(t) = n]\right]
$$</p>
<p>where $ \lambda = \frac{E[N(t)]}{t} $. This formula computes the expected claim size and arrival time, conditioned on the number of claims up to time $ t $.</p>
<h2 id="25-poisson-process-in-an-mmk-queue">§2.5 Poisson Process in an M/M/K Queue</h2>
<p>Consider an M/M/K queue with a general service time distribution $ G $ and a Poisson arrival process with rate $ \lambda $. Let $ \mathbb{Z}(t) $ denote the total number of customers served by time $ t $. Due to the memoryless property of the Poisson process, the number of customers arriving during the interval $ [t - s, t] $ follows a Poisson distribution with mean $ \lambda s $.</p>
<p>The expected number of customers served by time $ t $ is approximated by:</p>
<p>$$
E[\mathbb{Z}(t)] = \lambda \int_0^t \left(1 - F_T(t - s)\right) (t - s) ds
$$</p>
<p>where $ F_T $ is the cumulative distribution function of the service time distribution $ G $.</p>

			</div>

		</article>
	</div>
	<div class="blog container">
   <div class="head-blog">
    <h3>Related article</h3>
   </div>
<ul class="article-list">

 </ul>
</div>


</div>
<footer class="footer">
    <p><a href="https://gohugo.io">Hugo Cat</a></p>
    <p>Forkme on <a href="https://github.com/httpsecure/hugo-cat">Github</a></p>
</footer>


</body>
</html>